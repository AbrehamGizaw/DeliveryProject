{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Statistics:\n",
      "             Trip ID\n",
      "count  5.360200e+05\n",
      "mean   9.910221e+05\n",
      "std    3.456364e+05\n",
      "min    3.919960e+05\n",
      "25%    6.935610e+05\n",
      "50%    9.910085e+05\n",
      "75%    1.281570e+06\n",
      "max    1.637709e+06\n",
      "basic statistics of \n",
      "                  id      order_id     driver_id           lat           lng  \\\n",
      "count  1.557740e+06  1.557740e+06  1.557740e+06  1.557740e+06  1.557740e+06   \n",
      "mean   7.788705e+05  4.191833e+05  2.341505e+05  6.536031e+00  3.378877e+00   \n",
      "std    4.496809e+05  1.444531e+04  2.270475e+04  5.998150e-02  5.333432e-02   \n",
      "min    1.000000e+00  3.920010e+05  1.219810e+05  6.409333e+00  3.076561e+00   \n",
      "25%    3.894358e+05  4.067650e+05  2.429970e+05  6.498694e+00  3.348810e+00   \n",
      "50%    7.788705e+05  4.216870e+05  2.435890e+05  6.544247e+00  3.363504e+00   \n",
      "75%    1.168305e+06  4.293130e+05  2.440560e+05  6.593276e+00  3.385177e+00   \n",
      "max    1.557740e+06  5.179480e+05  2.478770e+05  7.702536e+00  8.515414e+00   \n",
      "\n",
      "       created_at  updated_at  \n",
      "count         0.0         0.0  \n",
      "mean          NaN         NaN  \n",
      "std           NaN         NaN  \n",
      "min           NaN         NaN  \n",
      "25%           NaN         NaN  \n",
      "50%           NaN         NaN  \n",
      "75%           NaN         NaN  \n",
      "max           NaN         NaN  \n",
      "Missing Values:\n",
      " Trip ID                0\n",
      "Trip Origin            0\n",
      "Trip Destination       0\n",
      "Trip Start Time     1651\n",
      "Trip End Time          1\n",
      "dtype: int64\n",
      "Missing values: \n",
      " id                     0\n",
      "order_id               0\n",
      "driver_id              0\n",
      "driver_action          0\n",
      "lat                    0\n",
      "lng                    0\n",
      "created_at       1557740\n",
      "updated_at       1557740\n",
      "dtype: int64\n",
      "completed data head \n",
      "    Trip ID                         Trip Origin  \\\n",
      "0   391996  6.508813001668548,3.37740316890347   \n",
      "1   391997                 6.4316714,3.4555375   \n",
      "2   391998         6.631679399999999,3.3388976   \n",
      "3   391999         6.572757200000001,3.3677082   \n",
      "4   392001                 6.6010417,3.2766339   \n",
      "\n",
      "                  Trip Destination      Trip Start Time        Trip End Time  \n",
      "0      6.650969799999999,3.3450307  2021-07-01 07:28:04  2021-07-01 07:29:37  \n",
      "1  6.4280814653326,3.4721885847586  2021-07-01 06:38:04  2021-07-01 07:07:28  \n",
      "2      6.508324099999999,3.3590397  2021-07-01 06:21:02  2021-07-01 07:02:23  \n",
      "3      6.584881099999999,3.3614073  2021-07-01 07:16:07  2021-07-01 07:29:42  \n",
      "4              6.4501069,3.3916154  2021-07-01 09:30:59  2021-07-01 09:34:36  \n",
      "total order data head \n",
      "    id  order_id  driver_id driver_action       lat       lng  created_at  \\\n",
      "0   1    392001     243828      accepted  6.602207  3.270465         NaN   \n",
      "1   2    392001     243588      rejected  6.592097  3.287445         NaN   \n",
      "2   3    392001     243830      rejected  6.596133  3.281784         NaN   \n",
      "3   4    392001     243539      rejected  6.596142  3.280526         NaN   \n",
      "4   5    392001     171653      rejected  6.609232  3.288800         NaN   \n",
      "\n",
      "   updated_at  \n",
      "0         NaN  \n",
      "1         NaN  \n",
      "2         NaN  \n",
      "3         NaN  \n",
      "4         NaN  \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/tenacademy/DeliveryProject/venv/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:218\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 218\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[0;32m~/tenacademy/DeliveryProject/venv/lib/python3.10/site-packages/pandas/core/computation/expressions.py:242\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[0;32m--> 242\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[0;32m~/tenacademy/DeliveryProject/venv/lib/python3.10/site-packages/pandas/core/computation/expressions.py:73\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m     72\u001b[0m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompleted data head \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, completed_dt\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal order data head \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, order_dt\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m---> 26\u001b[0m completed_dt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrip duration\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mcompleted_dt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTrip End Time\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcompleted_dt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTrip Start Time\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe following is completed data with trip duration less than zero \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, completed_dt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrip duration\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Outlier detection (example: using Z-score)\u001b[39;00m\n",
      "File \u001b[0;32m~/tenacademy/DeliveryProject/venv/lib/python3.10/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tenacademy/DeliveryProject/venv/lib/python3.10/site-packages/pandas/core/arraylike.py:194\u001b[0m, in \u001b[0;36mOpsMixin.__sub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sub__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tenacademy/DeliveryProject/venv/lib/python3.10/site-packages/pandas/core/series.py:6135\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[1;32m   6134\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_for_op(other)\n\u001b[0;32m-> 6135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexOpsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tenacademy/DeliveryProject/venv/lib/python3.10/site-packages/pandas/core/base.py:1382\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   1379\u001b[0m     rvalues \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(rvalues\u001b[38;5;241m.\u001b[39mstart, rvalues\u001b[38;5;241m.\u001b[39mstop, rvalues\u001b[38;5;241m.\u001b[39mstep)\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1382\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(result, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/tenacademy/DeliveryProject/venv/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:283\u001b[0m, in \u001b[0;36marithmetic_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    279\u001b[0m     _bool_arith_check(op, left, right)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[0;32m~/tenacademy/DeliveryProject/venv/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:227\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    221\u001b[0m         left\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(right, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m\n\u001b[1;32m    222\u001b[0m     ):\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n\u001b[0;32m--> 227\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43m_masked_arith_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/tenacademy/DeliveryProject/venv/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:163\u001b[0m, in \u001b[0;36m_masked_arith_op\u001b[0;34m(x, y, op)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# See GH#5284, GH#5035, GH#19448 for historical reference\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m--> 163\u001b[0m         result[mask] \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxrav\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myrav\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(y):\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datashader as ds\n",
    "import datashader.transfer_functions as tf\n",
    "from datashader.mpl_ext import dsshow\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Load data\n",
    "completed_dt = pd.read_csv('../data/nb.csv')\n",
    "order_dt = pd.read_csv('../data/driver_locations_during_request.csv')\n",
    "\n",
    "# Basic statistics\n",
    "print(\"Basic Statistics:\\n\", completed_dt.describe())\n",
    "print(\"basic statistics of \\n\", order_dt.describe())\n",
    "\n",
    "\n",
    "# Missing values\n",
    "print(\"Missing Values:\\n\", completed_dt.isnull().sum())\n",
    "print(\"Missing values: \\n\", order_dt.isnull().sum())\n",
    "\n",
    "print(\"completed data head \\n\", completed_dt.head())\n",
    "print(\"total order data head \\n\", order_dt.head())\n",
    "\n",
    "\n",
    "completed_dt['Trip Start Time']=pd.to_datetime(completed_dt['Trip Start Time'])\n",
    "completed_dt['Trip End Time']=pd.to_datetime(completed_dt['Trip End Time'])\n",
    "completed_dt['trip duration'] = completed_dt['Trip End Time'] - completed_dt['Trip Start Time']\n",
    "print(\"the following is completed data with trip duration less than zero \\n\", completed_dt[\"trip duration\"]<=0)\n",
    "# Outlier detection (example: using Z-score)\n",
    "z_scores = np.abs((completed_dt - completed_dt.mean()) / completed_dt.std())\n",
    "completed_dt = completed_dt[(z_scores < 3).all(axis=1)]\n",
    "\n",
    "# # Treat missing values (example: fill with median)\n",
    "# completed_dt.fillna(completed_dt.mean(), inplace=True)\n",
    "\n",
    "# # Basic visualizations\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.histplot(completed_dt['order_location_latitude'], kde=True)\n",
    "# plt.title('Distribution of Order Location Latitude')\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.histplot(completed_dt['order_location_longitude'], kde=True)\n",
    "# plt.title('Distribution of Order Location Longitude')\n",
    "# plt.show()\n",
    "s\n",
    "# # Geospatial Visualization using Datashader\n",
    "# canvas = ds.Canvas(plot_width=400, plot_height=400)\n",
    "# agg = canvas.points(completed_dt, 'order_location_longitude', 'order_location_latitude')\n",
    "# img = tf.shade(agg)\n",
    "# tf.set_background(img, \"black\").to_pil().show()\n",
    "\n",
    "# # More detailed visualizations and insights\n",
    "# # Correlation heatmap\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# sns.heatmap(completed_dt.corr(), annot=True, cmap='coolwarm')\n",
    "# plt.title('Correlation Heatmap')\n",
    "# plt.show()\n",
    "\n",
    "# # Save cleaned data\n",
    "# completed_dt.to_csv('data/cleaned_geospatial_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Additional feature creation based on time and location\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_time\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_time\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Extracting features from datetime\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Additional feature creation based on time and location\n",
    "completed_dt['Trip Start Time'] = pd.to_datetime(completed_dt['Trip Start Time'])\n",
    "completed_dt['end_time'] = pd.to_datetime(completed_dt['end_time'])\n",
    "\n",
    "# Extracting features from datetime\n",
    "completed_dt['hour_of_day'] = completed_dt['start_time'].dt.hour\n",
    "completed_dt['day_of_week'] = completed_dt['start_time'].dt.dayofweek\n",
    "completed_dt['is_weekend'] = completed_dt['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "# Placeholder for external data features (rain, holiday, traffic)\n",
    "# You would need to merge external data sources for actual implementation\n",
    "completed_dt['rain'] = np.random.choice([0, 1], size=len(completed_dt))  # Placeholder\n",
    "completed_dt['holiday'] = np.random.choice([0, 1], size=len(completed_dt))  # Placeholder\n",
    "completed_dt['traffic_condition'] = np.random.choice(['low', 'medium', 'high'], size=len(completed_dt))  # Placeholder\n",
    "\n",
    "# One-hot encode categorical features\n",
    "completed_dt = pd.get_dummies(completed_dt, columns=['traffic_condition'], drop_first=True)\n",
    "\n",
    "# Feature extraction example - travel time\n",
    "df['travel_time'] = (df['end_time'] - df['start_time']).dt.total_seconds() / 60  # in minutes\n",
    "\n",
    "print(\"Head of dataframe with new features:\\n\", df.head())\n",
    "\n",
    "# Save the dataframe with new features\n",
    "completed_dt.to_csv('data/enriched_geospatial_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Feature scaling\u001b[39;00m\n\u001b[1;32m      2\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m----> 3\u001b[0m df_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      4\u001b[0m df_scaled[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder_location_latitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder_location_longitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtravel_time\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(df_scaled[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder_location_latitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder_location_longitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtravel_time\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHead of scaled dataframe:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, df_scaled\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "df_scaled = df.copy()\n",
    "df_scaled[['order_location_latitude', 'order_location_longitude', 'travel_time']] = scaler.fit_transform(df_scaled[['order_location_latitude', 'order_location_longitude', 'travel_time']])\n",
    "\n",
    "print(\"Head of scaled dataframe:\\n\", df_scaled.head())\n",
    "\n",
    "# Save the scaled dataframe\n",
    "df_scaled.to_csv('data/scaled_geospatial_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geopy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgeopy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m geodesic\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_distance\u001b[39m(row):\n\u001b[1;32m      4\u001b[0m     start_coords \u001b[38;5;241m=\u001b[39m (row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdriver_location_latitude\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdriver_location_longitude\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'geopy'"
     ]
    }
   ],
   "source": [
    "from geopy.distance import geodesic\n",
    "\n",
    "def compute_distance(row):\n",
    "    start_coords = (row['driver_location_latitude'], row['driver_location_longitude'])\n",
    "    end_coords = (row['order_destination_latitude'], row['order_destination_longitude'])\n",
    "    return geodesic(start_coords, end_coords).meters\n",
    "\n",
    "df['distance_m'] = df.apply(compute_distance, axis=1)\n",
    "\n",
    "# Compute driving speed (placeholder example)\n",
    "df['driving_speed'] = df['distance_m'] / df['travel_time']  # in meters per minute\n",
    "\n",
    "print(\"Head of dataframe with distance and speed:\\n\", df.head())\n",
    "\n",
    "# Save the dataframe with distance and speed\n",
    "df.to_csv('data/feature_enriched_geospatial_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KDTree\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Create KDTree for efficient radius searches\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m locations \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder_location_latitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder_location_longitude\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      5\u001b[0m kdtree \u001b[38;5;241m=\u001b[39m KDTree(locations)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcount_neighbors_within_radius\u001b[39m(row, radius\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import KDTree\n",
    "\n",
    "# Create KDTree for efficient radius searches\n",
    "locations = df[['order_location_latitude', 'order_location_longitude']].values\n",
    "kdtree = KDTree(locations)\n",
    "\n",
    "def count_neighbors_within_radius(row, radius=500):\n",
    "    point = (row['order_location_latitude'], row['order_location_longitude'])\n",
    "    indices = kdtree.query_ball_point(point, radius / 1000)  # radius in km\n",
    "    return len(indices)\n",
    "\n",
    "df['riders_within_500m'] = df.apply(count_neighbors_within_radius, axis=1)\n",
    "\n",
    "print(\"Head of dataframe with riders within 500m:\\n\", df.head())\n",
    "\n",
    "# Save the dataframe with riders count\n",
    "df.to_csv('data/riders_enriched_geospatial_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Clustering starting locations\u001b[39;00m\n\u001b[1;32m      4\u001b[0m kmeans_start \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_location_cluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kmeans_start\u001b[38;5;241m.\u001b[39mfit_predict(\u001b[43mdf\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdriver_location_latitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdriver_location_longitude\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Clustering destination locations\u001b[39;00m\n\u001b[1;32m      8\u001b[0m kmeans_dest \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Clustering starting locations\n",
    "kmeans_start = KMeans(n_clusters=5)\n",
    "df['start_location_cluster'] = kmeans_start.fit_predict(df[['driver_location_latitude', 'driver_location_longitude']])\n",
    "\n",
    "# Clustering destination locations\n",
    "kmeans_dest = KMeans(n_clusters=5)\n",
    "df['destination_location_cluster'] = kmeans_dest.fit_predict(df[['order_destination_latitude', 'order_destination_longitude']])\n",
    "\n",
    "print(\"Head of dataframe with clusters:\\n\", df.head())\n",
    "\n",
    "# Save the dataframe with clusters\n",
    "df.to_csv('data/clustered_geospatial_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Purpose-driven visualization using Datashader\u001b[39;00m\n\u001b[1;32m      2\u001b[0m canvas \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mCanvas(plot_width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m800\u001b[39m, plot_height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m800\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m agg \u001b[38;5;241m=\u001b[39m canvas\u001b[38;5;241m.\u001b[39mpoints(\u001b[43mdf\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder_location_longitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder_location_latitude\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m img \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mshade(agg)\n\u001b[1;32m      5\u001b[0m tf\u001b[38;5;241m.\u001b[39mset_background(img, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto_pil()\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Purpose-driven visualization using Datashader\n",
    "canvas = ds.Canvas(plot_width=800, plot_height=800)\n",
    "agg = canvas.points(df, 'order_location_longitude', 'order_location_latitude')\n",
    "img = tf.shade(agg)\n",
    "tf.set_background(img, \"black\").to_pil().show()\n",
    "\n",
    "# Cluster visualization\n",
    "cluster_canvas = ds.Canvas(plot_width=800, plot_height=800)\n",
    "agg = cluster_canvas.points(df, 'order_location_longitude', 'order_location_latitude', ds.count_cat('start_location_cluster'))\n",
    "img = tf.shade(agg)\n",
    "tf.set_background(img, \"black\").to_pil().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
